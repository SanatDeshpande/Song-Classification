{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongDataTrain(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with np.load(path) as f:\n",
    "            data = f['X']\n",
    "            labels = list(f['T'])\n",
    "        self.data = torch.tensor(data)\n",
    "        label_set = set(labels)\n",
    "        mapping = {}\n",
    "        for count, i in enumerate(label_set):\n",
    "            mapping[i] = count\n",
    "        targets = np.zeros(len(labels))\n",
    "        for i in range(len(targets)):\n",
    "            targets[i] = mapping[labels[i]]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(self.targets)), len(self.targets), replace=False)\n",
    "        self.targets = self.targets[indices[int(.1 * len(self.targets)):]]\n",
    "        self.data = self.data[indices[int(.1 * len(self.data)):]]\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.targets[index])\n",
    "    def __len__(self):\n",
    "        return (len(self.targets))\n",
    "class SongDataTest(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with np.load(path) as f:\n",
    "            data = f['X']\n",
    "            labels = list(f['T'])\n",
    "        self.data = torch.tensor(data)\n",
    "        label_set = set(labels)\n",
    "        mapping = {}\n",
    "        for count, i in enumerate(label_set):\n",
    "            mapping[i] = count\n",
    "        targets = np.zeros(len(labels))\n",
    "        for i in range(len(targets)):\n",
    "            targets[i] = mapping[labels[i]]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(self.targets)), len(self.targets), replace=False)\n",
    "        self.targets = self.targets[indices[:int(.1 * len(self.targets))]]\n",
    "        self.data = self.data[indices[:int(.1 * len(self.data))]]\n",
    "        print(mapping)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.targets[index])\n",
    "    def __len__(self):\n",
    "        return (len(self.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h_t = torch.autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda()\n",
    "        h_c = torch.autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda()\n",
    "        return (h_t, h_c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'disco': 0, b'jazz': 1, b'classical': 2, b'country': 3, b'hiphop': 4, b'metal': 5, b'rock': 6, b'pop': 7, b'blues': 8, b'reggae': 9}\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_size = 2584\n",
    "batch_size = 100\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 10\n",
    "seq_len = 64\n",
    "\n",
    "dataset_train = SongDataTrain(\"./audio_sr_label.npz\") #initializes our dataset\n",
    "dataset_test = SongDataTest(\"./audio_sr_label.npz\") #initializes our dataset\n",
    "dataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)\n",
    "#double check ^^ above stuff\n",
    "\n",
    "#Model\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers, batch_size)\n",
    "\n",
    "#optimizer & criterion\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(model, test, seq_len, input_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    dataloader = dataloader_test if test == True else dataloader_train\n",
    "    for x, labels in dataloader:\n",
    "        x = x.reshape(-1, seq_len, input_size)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "        out = model(x)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        break\n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pred(model, seq_len, input_size):\n",
    "    model.eval()\n",
    "    predict = []\n",
    "    actual = []\n",
    "    for i, (x, labels) in enumerate(dataloader_test):\n",
    "        x = x.reshape(-1, seq_len, input_size)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "        out = model(x)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        predicted_n = predicted.cpu().data.numpy()\n",
    "        label_n = labels.cpu().data.numpy()\n",
    "        predict.append(predicted_n)\n",
    "        actual.append(label_n)\n",
    "    \n",
    "\n",
    "    with open(\"predict_lstm.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in predict]) + \",\")\n",
    "    with open(\"actual_lstm.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in actual]) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/9], Loss: 2.3029\n",
      "0.15 0.17\n",
      "Epoch [2/50], Step [1/9], Loss: 1.9589\n",
      "0.31 0.26\n",
      "Epoch [3/50], Step [1/9], Loss: 1.8601\n",
      "0.36 0.31\n",
      "Epoch [4/50], Step [1/9], Loss: 1.6501\n",
      "0.26 0.32\n",
      "Epoch [5/50], Step [1/9], Loss: 1.5341\n",
      "0.49 0.42\n",
      "Epoch [6/50], Step [1/9], Loss: 1.5270\n",
      "0.43 0.44\n",
      "Epoch [7/50], Step [1/9], Loss: 1.5257\n",
      "0.46 0.39\n",
      "Epoch [8/50], Step [1/9], Loss: 1.2617\n",
      "0.5 0.48\n",
      "Epoch [9/50], Step [1/9], Loss: 1.1894\n",
      "0.66 0.56\n",
      "Epoch [10/50], Step [1/9], Loss: 1.0287\n",
      "0.6 0.59\n",
      "Epoch [11/50], Step [1/9], Loss: 1.0177\n",
      "0.66 0.51\n",
      "Epoch [12/50], Step [1/9], Loss: 0.7784\n",
      "0.69 0.62\n",
      "Epoch [13/50], Step [1/9], Loss: 1.2160\n",
      "0.65 0.63\n",
      "Epoch [14/50], Step [1/9], Loss: 0.7082\n",
      "0.72 0.68\n",
      "Epoch [15/50], Step [1/9], Loss: 0.6887\n",
      "0.79 0.64\n",
      "Epoch [16/50], Step [1/9], Loss: 0.4538\n",
      "0.86 0.7\n",
      "Epoch [17/50], Step [1/9], Loss: 0.3638\n",
      "0.88 0.76\n",
      "Epoch [18/50], Step [1/9], Loss: 0.4952\n",
      "0.95 0.75\n",
      "Epoch [19/50], Step [1/9], Loss: 0.2532\n",
      "0.89 0.8\n",
      "Epoch [20/50], Step [1/9], Loss: 0.2754\n",
      "0.9 0.82\n",
      "Epoch [21/50], Step [1/9], Loss: 0.5415\n",
      "0.89 0.78\n",
      "Epoch [22/50], Step [1/9], Loss: 0.1417\n",
      "0.89 0.8\n",
      "Epoch [23/50], Step [1/9], Loss: 0.1715\n",
      "0.96 0.82\n",
      "Epoch [24/50], Step [1/9], Loss: 0.2719\n",
      "0.94 0.85\n",
      "Epoch [25/50], Step [1/9], Loss: 0.1416\n",
      "0.89 0.81\n",
      "Epoch [26/50], Step [1/9], Loss: 0.1921\n",
      "0.9 0.82\n",
      "Epoch [27/50], Step [1/9], Loss: 0.2138\n",
      "0.92 0.8\n",
      "Epoch [28/50], Step [1/9], Loss: 0.1515\n",
      "0.95 0.87\n",
      "Epoch [29/50], Step [1/9], Loss: 0.1113\n",
      "0.97 0.88\n",
      "Epoch [30/50], Step [1/9], Loss: 0.1174\n",
      "0.95 0.88\n",
      "Epoch [31/50], Step [1/9], Loss: 0.3315\n",
      "0.96 0.89\n",
      "Epoch [32/50], Step [1/9], Loss: 0.1030\n",
      "0.96 0.9\n",
      "Epoch [33/50], Step [1/9], Loss: 0.1758\n",
      "0.97 0.85\n",
      "Epoch [34/50], Step [1/9], Loss: 0.0770\n",
      "0.98 0.86\n",
      "Epoch [35/50], Step [1/9], Loss: 0.0499\n",
      "0.99 0.89\n",
      "Epoch [36/50], Step [1/9], Loss: 0.0294\n",
      "0.99 0.91\n",
      "Epoch [37/50], Step [1/9], Loss: 0.0275\n",
      "1.0 0.91\n",
      "Epoch [38/50], Step [1/9], Loss: 0.1285\n",
      "0.94 0.88\n",
      "Epoch [39/50], Step [1/9], Loss: 0.2180\n",
      "0.92 0.79\n",
      "Epoch [40/50], Step [1/9], Loss: 0.1825\n",
      "0.93 0.87\n",
      "Epoch [41/50], Step [1/9], Loss: 0.0593\n",
      "0.98 0.91\n",
      "Epoch [42/50], Step [1/9], Loss: 0.0216\n",
      "0.96 0.89\n",
      "Epoch [43/50], Step [1/9], Loss: 0.0145\n",
      "0.99 0.91\n",
      "Epoch [44/50], Step [1/9], Loss: 0.0256\n",
      "0.99 0.89\n",
      "Epoch [45/50], Step [1/9], Loss: 0.0861\n",
      "0.99 0.89\n",
      "Epoch [46/50], Step [1/9], Loss: 0.0783\n",
      "0.98 0.86\n",
      "Epoch [47/50], Step [1/9], Loss: 0.1007\n",
      "0.99 0.93\n",
      "Epoch [48/50], Step [1/9], Loss: 0.0865\n",
      "0.95 0.87\n",
      "Epoch [49/50], Step [1/9], Loss: 0.0078\n",
      "0.99 0.91\n",
      "Epoch [50/50], Step [1/9], Loss: 0.0395\n",
      "1.0 0.92\n"
     ]
    }
   ],
   "source": [
    "training_acc = []\n",
    "validation_acc = []\n",
    "losses = []\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (_data, _target) in enumerate(dataloader_train):\n",
    "        model.train()\n",
    "        model.hidden = model.init_hidden()\n",
    "        model.zero_grad()\n",
    "        _data = _data.type(torch.FloatTensor).cuda()\n",
    "        prediction = model(_data)\n",
    "        \n",
    "        loss = criterion(prediction, _target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, epochs, i+1, len(dataloader_train), loss.item()))\n",
    "            train_acc = assess(model, False, seq_len, input_size)\n",
    "            training_acc.append(train_acc)\n",
    "            val_acc = assess(model, True, seq_len, input_size)\n",
    "            validation_acc.append(val_acc)\n",
    "            losses.append(loss)\n",
    "            print(train_acc, val_acc)\n",
    "        \n",
    "        if epoch == 49 and i % 20 == 0:\n",
    "            val_pred = get_val_pred(model, seq_len, input_size)\n",
    "    \n",
    "    torch.save(model.state_dict(), \"./model\" + str(epoch).zfill(2))\n",
    "    \n",
    "with open(\"training_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in training_acc]) + \",\")\n",
    "with open(\"validation_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in validation_acc]) + \",\")\n",
    "with open(\"loss_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in losses]) + \",\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {b'metal': 0, b'jazz': 1, b'disco': 2, b'reggae': 3, b'country': 4, b'pop': 5, b'rock': 6, b'blues': 7, b'classical': 8, b'hiphop': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'metal': 0, b'jazz': 1, b'disco': 2, b'reggae': 3, b'country': 4, b'pop': 5, b'rock': 6, b'blues': 7, b'classical': 8, b'hiphop': 9}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

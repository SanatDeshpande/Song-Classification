{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongDataTrain(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with np.load(path) as f:\n",
    "            data = f['X']\n",
    "            labels = list(f['T'])\n",
    "        self.data = torch.tensor(data)\n",
    "        label_set = set(labels)\n",
    "        mapping = {}\n",
    "        for count, i in enumerate(label_set):\n",
    "            mapping[i] = count\n",
    "        targets = np.zeros(len(labels))\n",
    "        for i in range(len(targets)):\n",
    "            targets[i] = mapping[labels[i]]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(self.targets)), len(self.targets), replace=False)\n",
    "        self.targets = self.targets[indices[int(.1 * len(self.targets)):]]\n",
    "        self.data = self.data[indices[int(.1 * len(self.data)):]]\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.targets[index])\n",
    "    def __len__(self):\n",
    "        return (len(self.targets))\n",
    "class SongDataTest(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with np.load(path) as f:\n",
    "            data = f['X']\n",
    "            labels = list(f['T'])\n",
    "        self.data = torch.tensor(data)\n",
    "        label_set = set(labels)\n",
    "        mapping = {}\n",
    "        for count, i in enumerate(label_set):\n",
    "            mapping[i] = count\n",
    "        targets = np.zeros(len(labels))\n",
    "        for i in range(len(targets)):\n",
    "            targets[i] = mapping[labels[i]]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(self.targets)), len(self.targets), replace=False)\n",
    "        self.targets = self.targets[indices[:int(.1 * len(self.targets))]]\n",
    "        self.data = self.data[indices[:int(.1 * len(self.data))]]\n",
    "        print(mapping)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.targets[index])\n",
    "    def __len__(self):\n",
    "        return (len(self.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, batch_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h_t = torch.autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda()\n",
    "        h_c = torch.autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda()\n",
    "        return (h_t, h_c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x, self.hidden)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'country': 0, b'pop': 1, b'rock': 2, b'jazz': 3, b'disco': 4, b'blues': 5, b'metal': 6, b'reggae': 7, b'hiphop': 8, b'classical': 9}\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_size = 2584\n",
    "batch_size = 100\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 10\n",
    "seq_len = 64\n",
    "\n",
    "dataset_train = SongDataTrain(\"./audio_sr_label.npz\") #initializes our dataset\n",
    "dataset_test = SongDataTest(\"./audio_sr_label.npz\") #initializes our dataset\n",
    "dataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)\n",
    "#double check ^^ above stuff\n",
    "\n",
    "#Model\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers, batch_size)\n",
    "\n",
    "#optimizer & criterion\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(model, test, seq_len, input_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    dataloader = dataloader_test if test == True else dataloader_train\n",
    "    for x, labels in dataloader:\n",
    "        x = x.reshape(-1, seq_len, input_size)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "        out = model(x)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        break\n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pred(model, seq_len, input_size):\n",
    "    model.eval()\n",
    "    predict = []\n",
    "    actual = []\n",
    "    for i, (x, labels) in enumerate(dataloader_test):\n",
    "        x = x.reshape(-1, seq_len, input_size)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "        out = model(x)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        predicted_n = predicted.cpu().data.numpy()\n",
    "        label_n = labels.cpu().data.numpy()\n",
    "        predict.append(predicted_n)\n",
    "        actual.append(predicted_n)\n",
    "    \n",
    "\n",
    "    with open(\"predict_lstm.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in predict]) + \",\")\n",
    "    with open(\"actual_lstm.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in actual]) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/9], Loss: 2.3038\n",
      "0.12 0.05\n",
      "Epoch [2/50], Step [1/9], Loss: 1.8758\n",
      "0.26 0.2\n",
      "Epoch [3/50], Step [1/9], Loss: 1.7620\n",
      "0.35 0.31\n",
      "Epoch [4/50], Step [1/9], Loss: 1.6711\n",
      "0.36 0.39\n",
      "Epoch [5/50], Step [1/9], Loss: 1.6421\n",
      "0.41 0.3\n",
      "Epoch [6/50], Step [1/9], Loss: 1.3416\n",
      "0.5 0.47\n",
      "Epoch [7/50], Step [1/9], Loss: 1.3859\n",
      "0.49 0.41\n",
      "Epoch [8/50], Step [1/9], Loss: 1.5634\n",
      "0.56 0.49\n",
      "Epoch [9/50], Step [1/9], Loss: 1.0972\n",
      "0.63 0.52\n",
      "Epoch [10/50], Step [1/9], Loss: 1.1015\n",
      "0.66 0.62\n",
      "Epoch [11/50], Step [1/9], Loss: 1.0039\n",
      "0.7 0.58\n",
      "Epoch [12/50], Step [1/9], Loss: 0.6878\n",
      "0.66 0.7\n",
      "Epoch [13/50], Step [1/9], Loss: 0.7081\n",
      "0.81 0.72\n",
      "Epoch [14/50], Step [1/9], Loss: 0.4946\n",
      "0.82 0.81\n",
      "Epoch [15/50], Step [1/9], Loss: 0.5311\n",
      "0.77 0.77\n",
      "Epoch [16/50], Step [1/9], Loss: 0.6382\n",
      "0.86 0.75\n",
      "Epoch [17/50], Step [1/9], Loss: 0.4069\n",
      "0.8 0.77\n",
      "Epoch [18/50], Step [1/9], Loss: 0.3470\n",
      "0.82 0.81\n",
      "Epoch [19/50], Step [1/9], Loss: 0.3229\n",
      "0.9 0.83\n",
      "Epoch [20/50], Step [1/9], Loss: 0.2279\n",
      "0.92 0.81\n",
      "Epoch [21/50], Step [1/9], Loss: 0.2902\n",
      "0.96 0.85\n",
      "Epoch [22/50], Step [1/9], Loss: 0.2478\n",
      "0.92 0.86\n"
     ]
    }
   ],
   "source": [
    "training_acc = []\n",
    "validation_acc = []\n",
    "losses = []\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (_data, _target) in enumerate(dataloader_train):\n",
    "        model.train()\n",
    "        model.hidden = model.init_hidden()\n",
    "        model.zero_grad()\n",
    "        _data = _data.type(torch.FloatTensor).cuda()\n",
    "        prediction = model(_data)\n",
    "        \n",
    "        loss = criterion(prediction, _target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, epochs, i+1, len(dataloader_train), loss.item()))\n",
    "            train_acc = assess(model, False, seq_len, input_size)\n",
    "            training_acc.append(train_acc)\n",
    "            val_acc = assess(model, True, seq_len, input_size)\n",
    "            validation_acc.append(val_acc)\n",
    "            losses.append(loss)\n",
    "            print(train_acc, val_acc)\n",
    "        \n",
    "        if epoch == 49 and i % 20 == 0:\n",
    "            val_pred = get_val_pred(model, seq_len, input_size)\n",
    "    \n",
    "    torch.save(model.state_dict(), \"./model\" + str(epoch).zfill(2))\n",
    "    \n",
    "with open(\"training_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in training_acc]) + \",\")\n",
    "with open(\"validation_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in validation_acc]) + \",\")\n",
    "with open(\"loss_acc_lstm.csv\", \"a\") as f:\n",
    "    f.write(\",\".join([str(e) for e in losses]) + \",\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {b'metal': 0, b'jazz': 1, b'disco': 2, b'reggae': 3, b'country': 4, b'pop': 5, b'rock': 6, b'blues': 7, b'classical': 8, b'hiphop': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'metal': 0, b'jazz': 1, b'disco': 2, b'reggae': 3, b'country': 4, b'pop': 5, b'rock': 6, b'blues': 7, b'classical': 8, b'hiphop': 9}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

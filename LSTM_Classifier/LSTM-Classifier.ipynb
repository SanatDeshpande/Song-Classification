{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"./audio_sr_label.npz\") as f:\n",
    "    data = f['X']\n",
    "    labels = list(f['T'])\n",
    "data = np.asarray([[i[:2560] for i in j] for j in data])\n",
    "seed = data[:, :, :256]\n",
    "for i in range(1, 10):\n",
    "    seed = np.append(seed, data[:, :, i*256:(i+1)*256], axis=0)\n",
    "data = torch.tensor(seed, dtype=torch.float)\n",
    "labels = labels * 10 #expand dimensions accordingly\n",
    "label_set = set(labels)\n",
    "mapping = {}\n",
    "for count, i in enumerate(label_set):\n",
    "    mapping[i] = count\n",
    "targets = np.zeros(len(labels))\n",
    "for i in range(len(targets)):\n",
    "    targets[i] = mapping[labels[i]]\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "indices = np.random.choice(np.arange(len(targets)), len(targets), replace=False)\n",
    "train_index = indices[int(len(indices)/10):]\n",
    "test_index = indices[:int(len(indices)/10)]\n",
    "\n",
    "labels_train = targets[train_index]\n",
    "labels_test = targets[test_index]\n",
    "data_train = data[train_index]\n",
    "data_test = data[test_index]\n",
    "#double check ^^ above stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_t = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        h_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        output, (h_t, h_c) = self.lstm(x, (h_t, h_c))\n",
    "        output = self.fc(output[:, -1, :])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_size = 256\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 10\n",
    "seq_len = 64\n",
    "\n",
    "#Model\n",
    "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "#optimizer & criterion\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(model, songs, labels, seq_len, input_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(50):\n",
    "        index = np.random.randint(len(labels))\n",
    "        pred = model(songs[index].reshape(-1, seq_len, input_size))\n",
    "        if torch.argmax(pred, dim=1) == labels[index]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/9000], Loss: 2.3202\n",
      "Epoch [1/50], Step [101/9000], Loss: 2.3794\n",
      "Epoch [1/50], Step [201/9000], Loss: 2.3191\n",
      "Epoch [1/50], Step [301/9000], Loss: 2.3795\n",
      "Epoch [1/50], Step [401/9000], Loss: 2.3793\n",
      "Epoch [1/50], Step [501/9000], Loss: 2.2287\n",
      "Epoch [1/50], Step [601/9000], Loss: 2.3481\n",
      "Epoch [1/50], Step [701/9000], Loss: 2.3187\n"
     ]
    }
   ],
   "source": [
    "training_acc = []\n",
    "validation_acc = []\n",
    "model.train()\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(labels_train)):\n",
    "        index = np.random.randint(len(labels_train))\n",
    "        optimizer.zero_grad()\n",
    "        target = labels_train[index]\n",
    "        data = data_train[index].reshape(-1, seq_len, input_size)\n",
    "        prediction = model(data)\n",
    "        \n",
    "        loss = criterion(prediction, target.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, epochs, i+1, len(labels_train), loss.item()))\n",
    "        if i % 5 == 0:\n",
    "            if i % 20 == 0:\n",
    "                training_acc.append(assess(model, data_train, labels_train, seq_len, input_size))\n",
    "                validation_acc.append(assess(model, data_test, labels_test, seq_len, input_size))\n",
    "        \n",
    "    torch.save(model.state_dict(), \"./model\" + str(epoch).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

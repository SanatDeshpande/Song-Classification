{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=(3,5))\n",
    "        self.fc1 = nn.Linear(12544, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(.2)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 64, 256)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, (2,4))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x, (2,4))\n",
    "        x = x.view(-1, 12544)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(model, songs, labels):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(50):\n",
    "        index = np.random.randint(len(labels))\n",
    "        pred = model(songs[index])\n",
    "        if torch.argmax(pred, dim=1) == labels[index]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"../audio_sr_label.npz\") as f:\n",
    "    data = f['X']\n",
    "    labels = list(f['T'])\n",
    "data = np.asarray([[i[:2560] for i in j] for j in data])\n",
    "seed = data[:, :, :256]\n",
    "for i in range(1, 10):\n",
    "    seed = np.append(seed, data[:, :, i*256:(i+1)*256], axis=0)\n",
    "data = torch.tensor(seed, dtype=torch.float)\n",
    "labels = labels * 10 #expand dimensions accordingly\n",
    "label_set = set(labels)\n",
    "mapping = {}\n",
    "for count, i in enumerate(label_set):\n",
    "    mapping[i] = count\n",
    "targets = np.zeros(len(labels))\n",
    "for i in range(len(targets)):\n",
    "    targets[i] = mapping[labels[i]]\n",
    "targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(np.arange(len(targets)), len(targets), replace=False)\n",
    "train_index = indices[int(len(indices)/10):]\n",
    "test_index = indices[:int(len(indices)/10)]\n",
    "\n",
    "labels_train = targets[train_index]\n",
    "labels_test = targets[test_index]\n",
    "data_train = data[train_index]\n",
    "data_test = data[test_index]\n",
    "#double check ^^ above stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=1e-5)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    data_train.cuda()\n",
    "    data_test.cuda()\n",
    "    labels_train.cuda()\n",
    "    labels_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "0.1 0.02\n",
      "loss:  tensor(2.3238, grad_fn=<NllLossBackward>)\n",
      "0.2 0.22\n",
      "loss:  tensor(2.1420, grad_fn=<NllLossBackward>)\n",
      "0.12 0.14\n",
      "loss:  tensor(2.3046, grad_fn=<NllLossBackward>)\n",
      "0.16 0.08\n",
      "loss:  tensor(2.4423, grad_fn=<NllLossBackward>)\n",
      "0.1 0.22\n",
      "loss:  tensor(2.3062, grad_fn=<NllLossBackward>)\n",
      "0.16 0.1\n",
      "loss:  tensor(1.9647, grad_fn=<NllLossBackward>)\n",
      "0.22 0.18\n",
      "loss:  tensor(2.2185, grad_fn=<NllLossBackward>)\n",
      "0.28 0.22\n",
      "loss:  tensor(2.3739, grad_fn=<NllLossBackward>)\n",
      "0.26 0.26\n",
      "loss:  tensor(1.9721, grad_fn=<NllLossBackward>)\n",
      "0.24 0.26\n",
      "loss:  tensor(2.4071, grad_fn=<NllLossBackward>)\n",
      "0.26 0.3\n",
      "loss:  tensor(2.0522, grad_fn=<NllLossBackward>)\n",
      "0.16 0.18\n",
      "loss:  tensor(2.3676, grad_fn=<NllLossBackward>)\n",
      "0.28 0.26\n",
      "loss:  tensor(2.4401, grad_fn=<NllLossBackward>)\n",
      "0.26 0.36\n",
      "loss:  tensor(2.3944, grad_fn=<NllLossBackward>)\n",
      "0.3 0.24\n",
      "loss:  tensor(2.3877, grad_fn=<NllLossBackward>)\n",
      "0.34 0.36\n",
      "loss:  tensor(2.3991, grad_fn=<NllLossBackward>)\n",
      "0.2 0.38\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.28 0.24\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.36 0.28\n",
      "loss:  tensor(2.3432, grad_fn=<NllLossBackward>)\n",
      "0.3 0.32\n",
      "loss:  tensor(2.3992, grad_fn=<NllLossBackward>)\n",
      "0.28 0.36\n",
      "loss:  tensor(2.3971, grad_fn=<NllLossBackward>)\n",
      "0.34 0.36\n",
      "loss:  tensor(2.4485, grad_fn=<NllLossBackward>)\n",
      "0.28 0.38\n",
      "loss:  tensor(1.5216, grad_fn=<NllLossBackward>)\n",
      "0.28 0.28\n",
      "loss:  tensor(2.4352, grad_fn=<NllLossBackward>)\n",
      "0.32 0.32\n",
      "loss:  tensor(2.3221, grad_fn=<NllLossBackward>)\n",
      "0.36 0.36\n",
      "loss:  tensor(1.5021, grad_fn=<NllLossBackward>)\n",
      "0.28 0.36\n",
      "loss:  tensor(1.4670, grad_fn=<NllLossBackward>)\n",
      "0.26 0.3\n",
      "loss:  tensor(2.3986, grad_fn=<NllLossBackward>)\n",
      "0.32 0.4\n",
      "loss:  tensor(2.1524, grad_fn=<NllLossBackward>)\n",
      "0.44 0.4\n",
      "loss:  tensor(2.3112, grad_fn=<NllLossBackward>)\n",
      "0.3 0.36\n",
      "loss:  tensor(2.4521, grad_fn=<NllLossBackward>)\n",
      "0.34 0.32\n",
      "loss:  tensor(1.4676, grad_fn=<NllLossBackward>)\n",
      "0.36 0.28\n",
      "loss:  tensor(1.4864, grad_fn=<NllLossBackward>)\n",
      "0.26 0.42\n",
      "loss:  tensor(2.2255, grad_fn=<NllLossBackward>)\n",
      "0.36 0.36\n",
      "loss:  tensor(2.4111, grad_fn=<NllLossBackward>)\n",
      "0.26 0.34\n",
      "loss:  tensor(2.4058, grad_fn=<NllLossBackward>)\n",
      "0.4 0.34\n",
      "loss:  tensor(2.4541, grad_fn=<NllLossBackward>)\n",
      "0.24 0.5\n",
      "loss:  tensor(2.4380, grad_fn=<NllLossBackward>)\n",
      "0.36 0.42\n",
      "loss:  tensor(1.5120, grad_fn=<NllLossBackward>)\n",
      "0.3 0.24\n",
      "loss:  tensor(1.4814, grad_fn=<NllLossBackward>)\n",
      "0.34 0.48\n",
      "loss:  tensor(1.5071, grad_fn=<NllLossBackward>)\n",
      "0.34 0.46\n",
      "loss:  tensor(1.4708, grad_fn=<NllLossBackward>)\n",
      "0.38 0.48\n",
      "loss:  tensor(2.2425, grad_fn=<NllLossBackward>)\n",
      "0.36 0.22\n",
      "loss:  tensor(2.2917, grad_fn=<NllLossBackward>)\n",
      "0.2 0.34\n",
      "loss:  tensor(2.4388, grad_fn=<NllLossBackward>)\n",
      "0.32 0.46\n",
      "loss:  tensor(2.4014, grad_fn=<NllLossBackward>)\n",
      "0.34 0.44\n",
      "loss:  tensor(2.0253, grad_fn=<NllLossBackward>)\n",
      "0.38 0.34\n",
      "loss:  tensor(1.5296, grad_fn=<NllLossBackward>)\n",
      "0.32 0.46\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.36 0.3\n",
      "loss:  tensor(1.7243, grad_fn=<NllLossBackward>)\n",
      "0.44 0.4\n",
      "loss:  tensor(2.4607, grad_fn=<NllLossBackward>)\n",
      "0.42 0.5\n",
      "loss:  tensor(2.4502, grad_fn=<NllLossBackward>)\n",
      "0.3 0.46\n",
      "loss:  tensor(1.5901, grad_fn=<NllLossBackward>)\n",
      "0.34 0.4\n",
      "loss:  tensor(2.4579, grad_fn=<NllLossBackward>)\n",
      "0.32 0.44\n",
      "loss:  tensor(2.4210, grad_fn=<NllLossBackward>)\n",
      "0.42 0.42\n",
      "loss:  tensor(1.6208, grad_fn=<NllLossBackward>)\n",
      "0.36 0.5\n",
      "loss:  tensor(2.4131, grad_fn=<NllLossBackward>)\n",
      "0.3 0.42\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.36 0.64\n",
      "loss:  tensor(2.4049, grad_fn=<NllLossBackward>)\n",
      "0.38 0.42\n",
      "loss:  tensor(2.3978, grad_fn=<NllLossBackward>)\n",
      "0.46 0.46\n",
      "loss:  tensor(2.4451, grad_fn=<NllLossBackward>)\n",
      "0.48 0.46\n",
      "loss:  tensor(2.4514, grad_fn=<NllLossBackward>)\n",
      "0.48 0.46\n",
      "loss:  tensor(2.3908, grad_fn=<NllLossBackward>)\n",
      "0.28 0.52\n",
      "loss:  tensor(2.4594, grad_fn=<NllLossBackward>)\n",
      "0.36 0.4\n",
      "loss:  tensor(2.4273, grad_fn=<NllLossBackward>)\n",
      "0.44 0.5\n",
      "loss:  tensor(2.4040, grad_fn=<NllLossBackward>)\n",
      "0.46 0.34\n",
      "loss:  tensor(2.4172, grad_fn=<NllLossBackward>)\n",
      "0.44 0.58\n",
      "loss:  tensor(1.7048, grad_fn=<NllLossBackward>)\n",
      "0.44 0.36\n",
      "loss:  tensor(1.4623, grad_fn=<NllLossBackward>)\n",
      "0.46 0.48\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.46 0.48\n",
      "loss:  tensor(2.4230, grad_fn=<NllLossBackward>)\n",
      "0.4 0.34\n",
      "loss:  tensor(1.5880, grad_fn=<NllLossBackward>)\n",
      "0.46 0.36\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.36 0.34\n",
      "loss:  tensor(2.3947, grad_fn=<NllLossBackward>)\n",
      "0.32 0.44\n",
      "loss:  tensor(1.4910, grad_fn=<NllLossBackward>)\n",
      "0.44 0.38\n",
      "loss:  tensor(2.4532, grad_fn=<NllLossBackward>)\n",
      "0.46 0.48\n",
      "loss:  tensor(2.4528, grad_fn=<NllLossBackward>)\n",
      "0.34 0.5\n",
      "loss:  tensor(2.3385, grad_fn=<NllLossBackward>)\n",
      "0.38 0.48\n",
      "loss:  tensor(2.4590, grad_fn=<NllLossBackward>)\n",
      "0.42 0.58\n",
      "loss:  tensor(1.7249, grad_fn=<NllLossBackward>)\n",
      "0.42 0.5\n",
      "loss:  tensor(2.4607, grad_fn=<NllLossBackward>)\n",
      "0.42 0.48\n",
      "loss:  tensor(2.4085, grad_fn=<NllLossBackward>)\n",
      "0.46 0.34\n",
      "loss:  tensor(2.4217, grad_fn=<NllLossBackward>)\n",
      "0.32 0.4\n",
      "loss:  tensor(2.4113, grad_fn=<NllLossBackward>)\n",
      "0.56 0.44\n",
      "loss:  tensor(1.4623, grad_fn=<NllLossBackward>)\n",
      "0.36 0.32\n",
      "loss:  tensor(1.4662, grad_fn=<NllLossBackward>)\n",
      "0.38 0.4\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.56 0.38\n",
      "loss:  tensor(2.4385, grad_fn=<NllLossBackward>)\n",
      "0.5 0.46\n",
      "loss:  tensor(1.4618, grad_fn=<NllLossBackward>)\n",
      "0.36 0.58\n",
      "loss:  tensor(1.7238, grad_fn=<NllLossBackward>)\n",
      "0.38 0.5\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.46 0.36\n",
      "loss:  tensor(1.4791, grad_fn=<NllLossBackward>)\n",
      "0.4 0.42\n",
      "loss:  tensor(1.4619, grad_fn=<NllLossBackward>)\n",
      "0.38 0.36\n",
      "loss:  tensor(2.4598, grad_fn=<NllLossBackward>)\n",
      "0.46 0.44\n",
      "loss:  tensor(2.0008, grad_fn=<NllLossBackward>)\n",
      "0.36 0.42\n",
      "loss:  tensor(2.4556, grad_fn=<NllLossBackward>)\n",
      "0.4 0.44\n",
      "loss:  tensor(2.4560, grad_fn=<NllLossBackward>)\n",
      "0.44 0.38\n",
      "loss:  tensor(2.3936, grad_fn=<NllLossBackward>)\n",
      "0.42 0.34\n",
      "loss:  tensor(1.4744, grad_fn=<NllLossBackward>)\n",
      "0.46 0.54\n",
      "loss:  tensor(1.4829, grad_fn=<NllLossBackward>)\n",
      "0.48 0.54\n",
      "loss:  tensor(2.4389, grad_fn=<NllLossBackward>)\n",
      "0.44 0.58\n",
      "loss:  tensor(1.4778, grad_fn=<NllLossBackward>)\n",
      "0.52 0.46\n",
      "loss:  tensor(1.4620, grad_fn=<NllLossBackward>)\n",
      "0.32 0.56\n",
      "loss:  tensor(2.4355, grad_fn=<NllLossBackward>)\n",
      "0.48 0.52\n",
      "loss:  tensor(2.2787, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(2.4612, grad_fn=<NllLossBackward>)\n",
      "0.38 0.44\n",
      "loss:  tensor(2.2880, grad_fn=<NllLossBackward>)\n",
      "0.46 0.58\n",
      "loss:  tensor(1.8791, grad_fn=<NllLossBackward>)\n",
      "0.62 0.5\n",
      "loss:  tensor(2.4514, grad_fn=<NllLossBackward>)\n",
      "0.3 0.26\n",
      "loss:  tensor(2.4425, grad_fn=<NllLossBackward>)\n",
      "0.58 0.42\n",
      "loss:  tensor(2.4389, grad_fn=<NllLossBackward>)\n",
      "0.4 0.52\n",
      "loss:  tensor(2.4604, grad_fn=<NllLossBackward>)\n",
      "0.5 0.5\n",
      "loss:  tensor(1.5533, grad_fn=<NllLossBackward>)\n",
      "0.28 0.44\n",
      "loss:  tensor(2.2220, grad_fn=<NllLossBackward>)\n",
      "0.42 0.5\n",
      "loss:  tensor(1.6881, grad_fn=<NllLossBackward>)\n",
      "0.52 0.48\n",
      "loss:  tensor(2.3566, grad_fn=<NllLossBackward>)\n",
      "0.52 0.54\n",
      "loss:  tensor(2.4385, grad_fn=<NllLossBackward>)\n",
      "0.44 0.42\n",
      "loss:  tensor(1.4673, grad_fn=<NllLossBackward>)\n",
      "0.48 0.66\n",
      "loss:  tensor(1.5202, grad_fn=<NllLossBackward>)\n",
      "0.38 0.38\n",
      "loss:  tensor(2.4166, grad_fn=<NllLossBackward>)\n",
      "0.62 0.5\n",
      "loss:  tensor(1.4635, grad_fn=<NllLossBackward>)\n",
      "0.52 0.48\n",
      "loss:  tensor(2.3441, grad_fn=<NllLossBackward>)\n",
      "0.44 0.5\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.56 0.56\n",
      "loss:  tensor(1.4743, grad_fn=<NllLossBackward>)\n",
      "0.56 0.56\n",
      "loss:  tensor(2.4129, grad_fn=<NllLossBackward>)\n",
      "0.42 0.54\n",
      "loss:  tensor(1.5940, grad_fn=<NllLossBackward>)\n",
      "0.56 0.54\n",
      "loss:  tensor(1.5269, grad_fn=<NllLossBackward>)\n",
      "0.44 0.52\n",
      "loss:  tensor(2.4517, grad_fn=<NllLossBackward>)\n",
      "0.52 0.64\n",
      "loss:  tensor(2.1757, grad_fn=<NllLossBackward>)\n",
      "0.5 0.58\n",
      "loss:  tensor(1.5738, grad_fn=<NllLossBackward>)\n",
      "0.5 0.56\n",
      "loss:  tensor(2.3552, grad_fn=<NllLossBackward>)\n",
      "0.54 0.48\n",
      "loss:  tensor(2.4170, grad_fn=<NllLossBackward>)\n",
      "0.48 0.42\n",
      "loss:  tensor(2.3801, grad_fn=<NllLossBackward>)\n",
      "0.4 0.56\n",
      "loss:  tensor(1.9680, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(1.4621, grad_fn=<NllLossBackward>)\n",
      "0.5 0.54\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.48 0.56\n",
      "loss:  tensor(2.4534, grad_fn=<NllLossBackward>)\n",
      "0.56 0.54\n",
      "loss:  tensor(2.4171, grad_fn=<NllLossBackward>)\n",
      "0.54 0.4\n",
      "loss:  tensor(2.4485, grad_fn=<NllLossBackward>)\n",
      "0.52 0.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(2.4546, grad_fn=<NllLossBackward>)\n",
      "0.6 0.56\n",
      "loss:  tensor(1.4660, grad_fn=<NllLossBackward>)\n",
      "0.58 0.52\n",
      "loss:  tensor(2.3880, grad_fn=<NllLossBackward>)\n",
      "0.44 0.52\n",
      "loss:  tensor(2.4431, grad_fn=<NllLossBackward>)\n",
      "0.5 0.46\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.44 0.6\n",
      "loss:  tensor(1.5897, grad_fn=<NllLossBackward>)\n",
      "0.44 0.42\n",
      "loss:  tensor(2.4393, grad_fn=<NllLossBackward>)\n",
      "0.54 0.66\n",
      "loss:  tensor(1.8978, grad_fn=<NllLossBackward>)\n",
      "0.64 0.48\n",
      "loss:  tensor(2.4609, grad_fn=<NllLossBackward>)\n",
      "0.54 0.72\n",
      "loss:  tensor(1.4900, grad_fn=<NllLossBackward>)\n",
      "0.48 0.56\n",
      "loss:  tensor(1.9033, grad_fn=<NllLossBackward>)\n",
      "0.66 0.44\n",
      "loss:  tensor(2.4577, grad_fn=<NllLossBackward>)\n",
      "0.52 0.46\n",
      "loss:  tensor(1.4747, grad_fn=<NllLossBackward>)\n",
      "0.58 0.42\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.54 0.52\n",
      "loss:  tensor(1.7480, grad_fn=<NllLossBackward>)\n",
      "0.4 0.48\n",
      "loss:  tensor(2.3923, grad_fn=<NllLossBackward>)\n",
      "0.44 0.44\n",
      "loss:  tensor(2.4452, grad_fn=<NllLossBackward>)\n",
      "0.48 0.5\n",
      "loss:  tensor(2.4260, grad_fn=<NllLossBackward>)\n",
      "0.46 0.42\n",
      "loss:  tensor(1.5528, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(2.3121, grad_fn=<NllLossBackward>)\n",
      "0.54 0.46\n",
      "loss:  tensor(2.4457, grad_fn=<NllLossBackward>)\n",
      "0.56 0.4\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.68 0.5\n",
      "loss:  tensor(2.4604, grad_fn=<NllLossBackward>)\n",
      "0.54 0.6\n",
      "loss:  tensor(1.4892, grad_fn=<NllLossBackward>)\n",
      "0.46 0.52\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.52 0.48\n",
      "loss:  tensor(2.4069, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(1.5319, grad_fn=<NllLossBackward>)\n",
      "0.44 0.56\n",
      "loss:  tensor(1.4967, grad_fn=<NllLossBackward>)\n",
      "0.6 0.58\n",
      "loss:  tensor(2.4040, grad_fn=<NllLossBackward>)\n",
      "0.62 0.48\n",
      "loss:  tensor(2.4566, grad_fn=<NllLossBackward>)\n",
      "0.54 0.54\n",
      "loss:  tensor(2.4372, grad_fn=<NllLossBackward>)\n",
      "0.44 0.52\n",
      "loss:  tensor(2.4068, grad_fn=<NllLossBackward>)\n",
      "0.42 0.46\n",
      "loss:  tensor(2.4484, grad_fn=<NllLossBackward>)\n",
      "0.48 0.66\n",
      "loss:  tensor(2.4561, grad_fn=<NllLossBackward>)\n",
      "0.48 0.68\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.4 0.44\n",
      "loss:  tensor(1.4645, grad_fn=<NllLossBackward>)\n",
      "0.52 0.46\n",
      "loss:  tensor(1.4991, grad_fn=<NllLossBackward>)\n",
      "0.58 0.48\n",
      "loss:  tensor(1.4630, grad_fn=<NllLossBackward>)\n",
      "0.58 0.54\n",
      "loss:  tensor(2.4452, grad_fn=<NllLossBackward>)\n",
      "0.56 0.48\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.48 0.58\n",
      "loss:  tensor(1.6585, grad_fn=<NllLossBackward>)\n",
      "0.48 0.48\n",
      "loss:  tensor(1.5967, grad_fn=<NllLossBackward>)\n",
      "0.52 0.56\n",
      "loss:  tensor(1.4937, grad_fn=<NllLossBackward>)\n",
      "0.52 0.66\n",
      "loss:  tensor(1.5636, grad_fn=<NllLossBackward>)\n",
      "0.54 0.54\n",
      "loss:  tensor(1.6143, grad_fn=<NllLossBackward>)\n",
      "0.54 0.56\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.44 0.46\n",
      "loss:  tensor(2.4118, grad_fn=<NllLossBackward>)\n",
      "0.5 0.56\n",
      "loss:  tensor(1.4621, grad_fn=<NllLossBackward>)\n",
      "0.44 0.5\n",
      "loss:  tensor(2.1270, grad_fn=<NllLossBackward>)\n",
      "0.5 0.58\n",
      "loss:  tensor(2.4299, grad_fn=<NllLossBackward>)\n",
      "0.6 0.42\n",
      "loss:  tensor(2.4499, grad_fn=<NllLossBackward>)\n",
      "0.64 0.68\n",
      "loss:  tensor(1.4715, grad_fn=<NllLossBackward>)\n",
      "0.52 0.64\n",
      "loss:  tensor(2.3861, grad_fn=<NllLossBackward>)\n",
      "0.56 0.6\n",
      "loss:  tensor(2.4609, grad_fn=<NllLossBackward>)\n",
      "0.64 0.6\n",
      "loss:  tensor(1.5023, grad_fn=<NllLossBackward>)\n",
      "0.64 0.54\n",
      "loss:  tensor(1.9575, grad_fn=<NllLossBackward>)\n",
      "0.5 0.46\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.7 0.48\n",
      "loss:  tensor(1.5332, grad_fn=<NllLossBackward>)\n",
      "0.56 0.44\n",
      "loss:  tensor(2.4356, grad_fn=<NllLossBackward>)\n",
      "0.62 0.56\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.44 0.5\n",
      "loss:  tensor(2.0211, grad_fn=<NllLossBackward>)\n",
      "0.5 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.6\n",
      "loss:  tensor(1.4847, grad_fn=<NllLossBackward>)\n",
      "0.48 0.56\n",
      "loss:  tensor(2.4021, grad_fn=<NllLossBackward>)\n",
      "0.64 0.62\n",
      "loss:  tensor(1.6408, grad_fn=<NllLossBackward>)\n",
      "0.56 0.6\n",
      "loss:  tensor(1.5087, grad_fn=<NllLossBackward>)\n",
      "0.52 0.52\n",
      "loss:  tensor(1.4671, grad_fn=<NllLossBackward>)\n",
      "0.6 0.58\n",
      "loss:  tensor(1.4623, grad_fn=<NllLossBackward>)\n",
      "0.6 0.5\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.62 0.56\n",
      "loss:  tensor(1.9947, grad_fn=<NllLossBackward>)\n",
      "0.62 0.42\n",
      "loss:  tensor(1.4617, grad_fn=<NllLossBackward>)\n",
      "0.54 0.58\n",
      "loss:  tensor(2.4190, grad_fn=<NllLossBackward>)\n",
      "0.46 0.52\n",
      "loss:  tensor(2.4180, grad_fn=<NllLossBackward>)\n",
      "0.5 0.64\n",
      "loss:  tensor(2.3564, grad_fn=<NllLossBackward>)\n",
      "0.6 0.48\n",
      "loss:  tensor(1.4832, grad_fn=<NllLossBackward>)\n",
      "0.48 0.54\n",
      "loss:  tensor(1.5291, grad_fn=<NllLossBackward>)\n",
      "0.44 0.58\n",
      "loss:  tensor(1.4840, grad_fn=<NllLossBackward>)\n",
      "0.62 0.5\n",
      "loss:  tensor(2.1855, grad_fn=<NllLossBackward>)\n",
      "0.58 0.54\n",
      "loss:  tensor(1.4625, grad_fn=<NllLossBackward>)\n",
      "0.44 0.66\n",
      "loss:  tensor(1.9123, grad_fn=<NllLossBackward>)\n",
      "0.46 0.58\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.66 0.62\n",
      "loss:  tensor(2.3986, grad_fn=<NllLossBackward>)\n",
      "0.56 0.46\n",
      "loss:  tensor(1.7055, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(2.4099, grad_fn=<NllLossBackward>)\n",
      "0.52 0.5\n",
      "loss:  tensor(2.4340, grad_fn=<NllLossBackward>)\n",
      "0.54 0.48\n",
      "loss:  tensor(2.4393, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(1.4750, grad_fn=<NllLossBackward>)\n",
      "0.66 0.52\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.56 0.64\n",
      "loss:  tensor(1.5047, grad_fn=<NllLossBackward>)\n",
      "0.62 0.48\n",
      "loss:  tensor(2.4556, grad_fn=<NllLossBackward>)\n",
      "0.52 0.48\n",
      "loss:  tensor(2.3116, grad_fn=<NllLossBackward>)\n",
      "0.6 0.5\n",
      "loss:  tensor(1.4656, grad_fn=<NllLossBackward>)\n",
      "0.64 0.56\n",
      "loss:  tensor(1.4617, grad_fn=<NllLossBackward>)\n",
      "0.6 0.58\n",
      "loss:  tensor(1.4687, grad_fn=<NllLossBackward>)\n",
      "0.6 0.6\n",
      "loss:  tensor(1.4641, grad_fn=<NllLossBackward>)\n",
      "0.64 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.56 0.64\n",
      "loss:  tensor(2.3667, grad_fn=<NllLossBackward>)\n",
      "0.36 0.78\n",
      "loss:  tensor(2.1100, grad_fn=<NllLossBackward>)\n",
      "0.58 0.46\n",
      "loss:  tensor(1.4797, grad_fn=<NllLossBackward>)\n",
      "0.58 0.52\n",
      "loss:  tensor(2.1983, grad_fn=<NllLossBackward>)\n",
      "0.56 0.64\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.64 0.56\n",
      "loss:  tensor(1.5890, grad_fn=<NllLossBackward>)\n",
      "0.68 0.6\n",
      "loss:  tensor(2.4129, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(1.9735, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(1.4923, grad_fn=<NllLossBackward>)\n",
      "0.6 0.46\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.72 0.48\n",
      "loss:  tensor(2.4572, grad_fn=<NllLossBackward>)\n",
      "0.44 0.5\n",
      "loss:  tensor(1.6574, grad_fn=<NllLossBackward>)\n",
      "0.64 0.52\n",
      "loss:  tensor(1.5800, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(2.3041, grad_fn=<NllLossBackward>)\n",
      "0.72 0.54\n",
      "loss:  tensor(2.4609, grad_fn=<NllLossBackward>)\n",
      "0.58 0.6\n",
      "loss:  tensor(1.8540, grad_fn=<NllLossBackward>)\n",
      "0.58 0.6\n",
      "loss:  tensor(2.4216, grad_fn=<NllLossBackward>)\n",
      "0.66 0.6\n",
      "loss:  tensor(1.4924, grad_fn=<NllLossBackward>)\n",
      "0.62 0.52\n",
      "loss:  tensor(1.4630, grad_fn=<NllLossBackward>)\n",
      "0.54 0.5\n",
      "loss:  tensor(2.3770, grad_fn=<NllLossBackward>)\n",
      "0.76 0.54\n",
      "loss:  tensor(1.4647, grad_fn=<NllLossBackward>)\n",
      "0.62 0.54\n",
      "loss:  tensor(1.8938, grad_fn=<NllLossBackward>)\n",
      "0.5 0.5\n",
      "loss:  tensor(1.5422, grad_fn=<NllLossBackward>)\n",
      "0.64 0.56\n",
      "loss:  tensor(1.6087, grad_fn=<NllLossBackward>)\n",
      "0.56 0.58\n",
      "loss:  tensor(2.4445, grad_fn=<NllLossBackward>)\n",
      "0.46 0.62\n",
      "loss:  tensor(2.4519, grad_fn=<NllLossBackward>)\n",
      "0.74 0.48\n",
      "loss:  tensor(1.4651, grad_fn=<NllLossBackward>)\n",
      "0.48 0.44\n",
      "loss:  tensor(2.4406, grad_fn=<NllLossBackward>)\n",
      "0.5 0.62\n",
      "loss:  tensor(1.7036, grad_fn=<NllLossBackward>)\n",
      "0.58 0.58\n",
      "loss:  tensor(1.5171, grad_fn=<NllLossBackward>)\n",
      "0.64 0.64\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.56 0.62\n",
      "loss:  tensor(2.4248, grad_fn=<NllLossBackward>)\n",
      "0.46 0.56\n",
      "loss:  tensor(2.4378, grad_fn=<NllLossBackward>)\n",
      "0.62 0.58\n",
      "loss:  tensor(2.4226, grad_fn=<NllLossBackward>)\n",
      "0.58 0.7\n",
      "loss:  tensor(2.4579, grad_fn=<NllLossBackward>)\n",
      "0.6 0.52\n",
      "loss:  tensor(1.4766, grad_fn=<NllLossBackward>)\n",
      "0.7 0.58\n",
      "loss:  tensor(2.4600, grad_fn=<NllLossBackward>)\n",
      "0.66 0.58\n",
      "loss:  tensor(2.3045, grad_fn=<NllLossBackward>)\n",
      "0.72 0.62\n",
      "loss:  tensor(1.4637, grad_fn=<NllLossBackward>)\n",
      "0.62 0.52\n",
      "loss:  tensor(1.4966, grad_fn=<NllLossBackward>)\n",
      "0.68 0.66\n",
      "loss:  tensor(1.7053, grad_fn=<NllLossBackward>)\n",
      "0.52 0.56\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(2.4565, grad_fn=<NllLossBackward>)\n",
      "0.54 0.66\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.52 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.68 0.56\n",
      "loss:  tensor(1.4808, grad_fn=<NllLossBackward>)\n",
      "0.58 0.52\n",
      "loss:  tensor(1.4782, grad_fn=<NllLossBackward>)\n",
      "0.66 0.5\n",
      "loss:  tensor(2.3458, grad_fn=<NllLossBackward>)\n",
      "0.62 0.68\n",
      "loss:  tensor(2.4570, grad_fn=<NllLossBackward>)\n",
      "0.66 0.6\n",
      "loss:  tensor(2.4245, grad_fn=<NllLossBackward>)\n",
      "0.62 0.48\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.64 0.68\n",
      "loss:  tensor(1.5936, grad_fn=<NllLossBackward>)\n",
      "0.66 0.62\n",
      "loss:  tensor(1.4966, grad_fn=<NllLossBackward>)\n",
      "0.64 0.6\n",
      "loss:  tensor(1.5994, grad_fn=<NllLossBackward>)\n",
      "0.56 0.54\n",
      "loss:  tensor(2.2031, grad_fn=<NllLossBackward>)\n",
      "0.62 0.5\n",
      "loss:  tensor(2.2951, grad_fn=<NllLossBackward>)\n",
      "0.52 0.56\n",
      "loss:  tensor(1.5078, grad_fn=<NllLossBackward>)\n",
      "0.66 0.64\n",
      "loss:  tensor(1.6832, grad_fn=<NllLossBackward>)\n",
      "0.66 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.48\n",
      "loss:  tensor(1.5259, grad_fn=<NllLossBackward>)\n",
      "0.62 0.64\n",
      "loss:  tensor(1.4724, grad_fn=<NllLossBackward>)\n",
      "0.54 0.56\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.6 0.74\n",
      "loss:  tensor(1.4744, grad_fn=<NllLossBackward>)\n",
      "0.56 0.54\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.56 0.5\n",
      "loss:  tensor(1.4630, grad_fn=<NllLossBackward>)\n",
      "0.7 0.6\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(2.4600, grad_fn=<NllLossBackward>)\n",
      "0.64 0.7\n",
      "loss:  tensor(2.4558, grad_fn=<NllLossBackward>)\n",
      "0.58 0.5\n",
      "loss:  tensor(2.4231, grad_fn=<NllLossBackward>)\n",
      "0.6 0.62\n",
      "loss:  tensor(2.2503, grad_fn=<NllLossBackward>)\n",
      "0.78 0.58\n",
      "loss:  tensor(1.4629, grad_fn=<NllLossBackward>)\n",
      "0.52 0.68\n",
      "loss:  tensor(1.4829, grad_fn=<NllLossBackward>)\n",
      "0.58 0.64\n",
      "loss:  tensor(1.9833, grad_fn=<NllLossBackward>)\n",
      "0.74 0.54\n",
      "loss:  tensor(1.4694, grad_fn=<NllLossBackward>)\n",
      "0.56 0.56\n",
      "loss:  tensor(1.4715, grad_fn=<NllLossBackward>)\n",
      "0.46 0.62\n",
      "loss:  tensor(1.4638, grad_fn=<NllLossBackward>)\n",
      "0.7 0.64\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.62 0.5\n",
      "loss:  tensor(1.8378, grad_fn=<NllLossBackward>)\n",
      "0.66 0.62\n",
      "loss:  tensor(2.4495, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(1.6058, grad_fn=<NllLossBackward>)\n",
      "0.52 0.4\n",
      "loss:  tensor(2.4376, grad_fn=<NllLossBackward>)\n",
      "0.48 0.62\n",
      "loss:  tensor(2.1552, grad_fn=<NllLossBackward>)\n",
      "0.64 0.54\n",
      "loss:  tensor(1.4657, grad_fn=<NllLossBackward>)\n",
      "0.66 0.52\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(2.4361, grad_fn=<NllLossBackward>)\n",
      "0.62 0.52\n",
      "loss:  tensor(1.5127, grad_fn=<NllLossBackward>)\n",
      "0.62 0.68\n",
      "loss:  tensor(2.4155, grad_fn=<NllLossBackward>)\n",
      "0.56 0.64\n",
      "loss:  tensor(1.4685, grad_fn=<NllLossBackward>)\n",
      "0.64 0.62\n",
      "loss:  tensor(2.4019, grad_fn=<NllLossBackward>)\n",
      "0.62 0.48\n",
      "loss:  tensor(2.2014, grad_fn=<NllLossBackward>)\n",
      "0.62 0.66\n",
      "loss:  tensor(2.2841, grad_fn=<NllLossBackward>)\n",
      "0.66 0.46\n",
      "loss:  tensor(1.4622, grad_fn=<NllLossBackward>)\n",
      "0.56 0.48\n",
      "loss:  tensor(1.4736, grad_fn=<NllLossBackward>)\n",
      "0.68 0.64\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.7 0.54\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.56\n",
      "loss:  tensor(2.4483, grad_fn=<NllLossBackward>)\n",
      "0.58 0.74\n",
      "loss:  tensor(2.4123, grad_fn=<NllLossBackward>)\n",
      "0.6 0.62\n",
      "loss:  tensor(2.1620, grad_fn=<NllLossBackward>)\n",
      "0.68 0.66\n",
      "loss:  tensor(2.0800, grad_fn=<NllLossBackward>)\n",
      "0.56 0.48\n",
      "loss:  tensor(2.4076, grad_fn=<NllLossBackward>)\n",
      "0.62 0.58\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.44 0.6\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.5 0.54\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.54 0.52\n",
      "loss:  tensor(1.4846, grad_fn=<NllLossBackward>)\n",
      "0.54 0.56\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.62 0.56\n",
      "loss:  tensor(2.4552, grad_fn=<NllLossBackward>)\n",
      "0.58 0.64\n",
      "loss:  tensor(1.5554, grad_fn=<NllLossBackward>)\n",
      "0.58 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.68 0.7\n",
      "loss:  tensor(2.4607, grad_fn=<NllLossBackward>)\n",
      "0.6 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.7\n",
      "loss:  tensor(1.4685, grad_fn=<NllLossBackward>)\n",
      "0.72 0.68\n",
      "loss:  tensor(1.4615, grad_fn=<NllLossBackward>)\n",
      "0.74 0.54\n",
      "loss:  tensor(2.4612, grad_fn=<NllLossBackward>)\n",
      "0.6 0.56\n",
      "loss:  tensor(2.2073, grad_fn=<NllLossBackward>)\n",
      "0.68 0.68\n",
      "loss:  tensor(1.4615, grad_fn=<NllLossBackward>)\n",
      "0.68 0.54\n",
      "loss:  tensor(2.1596, grad_fn=<NllLossBackward>)\n",
      "0.56 0.7\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.48\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.6 0.56\n",
      "loss:  tensor(2.4610, grad_fn=<NllLossBackward>)\n",
      "0.78 0.58\n",
      "loss:  tensor(2.4597, grad_fn=<NllLossBackward>)\n",
      "0.64 0.64\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.46 0.6\n",
      "loss:  tensor(1.4924, grad_fn=<NllLossBackward>)\n",
      "0.74 0.66\n",
      "loss:  tensor(1.8736, grad_fn=<NllLossBackward>)\n",
      "0.62 0.54\n",
      "loss:  tensor(1.5634, grad_fn=<NllLossBackward>)\n",
      "0.72 0.64\n",
      "loss:  tensor(1.8066, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(2.2864, grad_fn=<NllLossBackward>)\n",
      "0.64 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(2.4207, grad_fn=<NllLossBackward>)\n",
      "0.74 0.64\n",
      "loss:  tensor(1.4619, grad_fn=<NllLossBackward>)\n",
      "0.76 0.66\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.72 0.7\n",
      "loss:  tensor(2.1335, grad_fn=<NllLossBackward>)\n",
      "0.6 0.48\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.54 0.66\n",
      "loss:  tensor(1.4909, grad_fn=<NllLossBackward>)\n",
      "0.56 0.54\n",
      "loss:  tensor(1.4657, grad_fn=<NllLossBackward>)\n",
      "0.7 0.54\n",
      "loss:  tensor(1.6585, grad_fn=<NllLossBackward>)\n",
      "0.68 0.46\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.76 0.66\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.56\n",
      "loss:  tensor(1.4663, grad_fn=<NllLossBackward>)\n",
      "0.66 0.6\n",
      "loss:  tensor(1.8168, grad_fn=<NllLossBackward>)\n",
      "0.68 0.7\n",
      "loss:  tensor(2.4251, grad_fn=<NllLossBackward>)\n",
      "0.6 0.68\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.62 0.52\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.7\n",
      "loss:  tensor(2.3104, grad_fn=<NllLossBackward>)\n",
      "0.68 0.46\n",
      "loss:  tensor(2.4202, grad_fn=<NllLossBackward>)\n",
      "0.66 0.66\n",
      "loss:  tensor(2.4425, grad_fn=<NllLossBackward>)\n",
      "0.64 0.7\n",
      "loss:  tensor(1.4649, grad_fn=<NllLossBackward>)\n",
      "0.64 0.64\n",
      "loss:  tensor(1.4630, grad_fn=<NllLossBackward>)\n",
      "0.64 0.62\n",
      "loss:  tensor(2.4169, grad_fn=<NllLossBackward>)\n",
      "0.52 0.7\n",
      "loss:  tensor(2.4311, grad_fn=<NllLossBackward>)\n",
      "0.64 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.6 0.64\n",
      "loss:  tensor(1.4615, grad_fn=<NllLossBackward>)\n",
      "0.68 0.62\n",
      "loss:  tensor(1.4628, grad_fn=<NllLossBackward>)\n",
      "0.74 0.5\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.56\n",
      "loss:  tensor(2.4390, grad_fn=<NllLossBackward>)\n",
      "0.66 0.58\n",
      "loss:  tensor(1.4626, grad_fn=<NllLossBackward>)\n",
      "0.7 0.56\n",
      "loss:  tensor(2.4595, grad_fn=<NllLossBackward>)\n",
      "0.64 0.66\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.68\n",
      "loss:  tensor(2.4116, grad_fn=<NllLossBackward>)\n",
      "0.62 0.62\n",
      "loss:  tensor(1.4649, grad_fn=<NllLossBackward>)\n",
      "0.52 0.6\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.48\n",
      "loss:  tensor(2.4442, grad_fn=<NllLossBackward>)\n",
      "0.52 0.64\n",
      "loss:  tensor(1.7989, grad_fn=<NllLossBackward>)\n",
      "0.62 0.6\n",
      "loss:  tensor(1.5655, grad_fn=<NllLossBackward>)\n",
      "0.7 0.66\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.5\n",
      "loss:  tensor(2.2993, grad_fn=<NllLossBackward>)\n",
      "0.68 0.72\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.68 0.62\n",
      "loss:  tensor(1.4663, grad_fn=<NllLossBackward>)\n",
      "0.62 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.68 0.7\n",
      "loss:  tensor(1.4780, grad_fn=<NllLossBackward>)\n",
      "0.6 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.64 0.64\n",
      "loss:  tensor(2.3562, grad_fn=<NllLossBackward>)\n",
      "0.56 0.62\n",
      "loss:  tensor(1.5006, grad_fn=<NllLossBackward>)\n",
      "0.76 0.62\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.64 0.46\n",
      "loss:  tensor(2.3454, grad_fn=<NllLossBackward>)\n",
      "0.56 0.68\n",
      "loss:  tensor(2.4395, grad_fn=<NllLossBackward>)\n",
      "0.62 0.74\n",
      "loss:  tensor(2.4393, grad_fn=<NllLossBackward>)\n",
      "0.54 0.64\n",
      "loss:  tensor(1.4680, grad_fn=<NllLossBackward>)\n",
      "0.56 0.7\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.62 0.64\n",
      "loss:  tensor(2.4436, grad_fn=<NllLossBackward>)\n",
      "0.7 0.6\n",
      "loss:  tensor(1.7742, grad_fn=<NllLossBackward>)\n",
      "0.54 0.54\n",
      "loss:  tensor(2.1774, grad_fn=<NllLossBackward>)\n",
      "0.7 0.62\n",
      "loss:  tensor(2.4525, grad_fn=<NllLossBackward>)\n",
      "0.66 0.62\n",
      "loss:  tensor(2.4293, grad_fn=<NllLossBackward>)\n",
      "0.52 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.8640, grad_fn=<NllLossBackward>)\n",
      "0.8 0.62\n",
      "loss:  tensor(1.4629, grad_fn=<NllLossBackward>)\n",
      "0.68 0.62\n",
      "loss:  tensor(2.4604, grad_fn=<NllLossBackward>)\n",
      "0.62 0.78\n",
      "loss:  tensor(1.4626, grad_fn=<NllLossBackward>)\n",
      "0.66 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.7 0.34\n",
      "loss:  tensor(2.4273, grad_fn=<NllLossBackward>)\n",
      "0.74 0.6\n",
      "loss:  tensor(2.4304, grad_fn=<NllLossBackward>)\n",
      "0.54 0.62\n",
      "loss:  tensor(1.5194, grad_fn=<NllLossBackward>)\n",
      "0.62 0.64\n",
      "loss:  tensor(1.4739, grad_fn=<NllLossBackward>)\n",
      "0.82 0.58\n",
      "loss:  tensor(1.7299, grad_fn=<NllLossBackward>)\n",
      "0.74 0.64\n",
      "loss:  tensor(1.4879, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.54 0.68\n",
      "loss:  tensor(2.4255, grad_fn=<NllLossBackward>)\n",
      "0.74 0.58\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.62 0.58\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.66 0.7\n",
      "loss:  tensor(1.9041, grad_fn=<NllLossBackward>)\n",
      "0.64 0.42\n",
      "loss:  tensor(2.2956, grad_fn=<NllLossBackward>)\n",
      "0.62 0.58\n",
      "loss:  tensor(2.4611, grad_fn=<NllLossBackward>)\n",
      "0.7 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.58 0.56\n",
      "loss:  tensor(2.0182, grad_fn=<NllLossBackward>)\n",
      "0.52 0.6\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.68 0.68\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.72 0.64\n",
      "loss:  tensor(1.4612, grad_fn=<NllLossBackward>)\n",
      "0.62 0.66\n",
      "loss:  tensor(1.6681, grad_fn=<NllLossBackward>)\n",
      "0.72 0.68\n",
      "loss:  tensor(1.4613, grad_fn=<NllLossBackward>)\n",
      "0.68 0.68\n",
      "loss:  tensor(1.7345, grad_fn=<NllLossBackward>)\n",
      "0.68 0.72\n",
      "loss:  tensor(2.4521, grad_fn=<NllLossBackward>)\n",
      "0.76 0.58\n",
      "loss:  tensor(1.4614, grad_fn=<NllLossBackward>)\n",
      "0.82 0.56\n",
      "loss:  tensor(2.1310, grad_fn=<NllLossBackward>)\n",
      "0.72 0.66\n",
      "loss:  tensor(2.4609, grad_fn=<NllLossBackward>)\n",
      "0.58 0.66\n"
     ]
    }
   ],
   "source": [
    "training_acc = []\n",
    "validation_acc = []\n",
    "model.train()\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(labels_train)):\n",
    "        index = np.random.randint(len(labels_train))\n",
    "        optimizer.zero_grad()\n",
    "        target = labels_train[index]\n",
    "        prediction = model(data_train[index])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(prediction, target.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if i % 200 == 0:\n",
    "#             training_acc.append(assess(model, data_train, labels_train))\n",
    "#             validation_acc.append(assess(model, data_test, labels_test))\n",
    "        if i % 1000 == 0:\n",
    "            train_checkpoint = assess(model, data_train, labels_train)\n",
    "            model.eval()\n",
    "            test_checkpoint = assess(model, data_test, labels_test)\n",
    "            model.train()\n",
    "            print(\"loss: \", loss)\n",
    "            print(train_checkpoint, test_checkpoint)\n",
    "            training_acc.append(train_checkpoint)\n",
    "            validation_acc.append(test_checkpoint)\n",
    "#                 with open(\"training_acc\", \"ab\") as f:\n",
    "#                     np.asarray(training_acc).tofile(f)\n",
    "#                 with open(\"validation_acc\", \"ab\") as f:\n",
    "#                     np.asarray(validation_acc).tofile(f)\n",
    "#                 training_acc = []\n",
    "#                 validation_acc = []\n",
    "    torch.save(model.state_dict(), \"./model\" + str(epoch).zfill(2))\n",
    "    with open(\"training.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in training_acc]) + \",\")\n",
    "    with open(\"testing.csv\", \"a\") as f:\n",
    "        f.write(\",\".join([str(e) for e in validation_acc]) + \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.274\n",
      "1 :  0.36\n",
      "2 :  0.363\n",
      "3 :  0.423\n",
      "4 :  0.449\n",
      "5 :  0.468\n",
      "6 :  0.464\n",
      "7 :  0.484\n",
      "8 :  0.507\n",
      "9 :  0.537\n",
      "10 :  0.532\n",
      "11 :  0.544\n",
      "12 :  0.586\n",
      "13 :  0.589\n",
      "14 :  0.59\n",
      "15 :  0.6\n",
      "16 :  0.619\n",
      "17 :  0.632\n",
      "18 :  0.62\n",
      "19 :  0.644\n",
      "20 :  0.662\n",
      "21 :  0.644\n",
      "22 :  0.646\n",
      "23 :  0.676\n",
      "24 :  0.672\n",
      "25 :  0.702\n",
      "26 :  0.674\n",
      "27 :  0.689\n",
      "28 :  0.7\n",
      "29 :  0.7\n",
      "30 :  0.722\n",
      "31 :  0.71\n",
      "32 :  0.73\n",
      "33 :  0.749\n",
      "34 :  0.737\n",
      "35 :  0.736\n",
      "36 :  0.742\n",
      "37 :  0.751\n",
      "38 :  0.752\n",
      "39 :  0.763\n",
      "40 :  0.771\n",
      "41 :  0.753\n",
      "42 :  0.762\n",
      "43 :  0.768\n",
      "44 :  0.755\n",
      "45 :  0.775\n",
      "46 :  0.777\n",
      "47 :  0.777\n",
      "48 :  0.788\n",
      "49 :  0.778\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "predicted_truth = []\n",
    "for epoch in range(epochs):\n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(\"./model\" + str(epoch).zfill(2)))\n",
    "    #model.load_state_dict(torch.load(\"./model\", map_location='cpu'))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(int(len(data)/10)):\n",
    "        y_hats = model(data[i])\n",
    "        for j in range(1, 10):\n",
    "            y_hats = torch.cat((y_hats, model(data[i + 1000*j])))\n",
    "        if torch.argmax(torch.sum(y_hats, dim=0)) == targets[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        ground_truth.append(torch.argmax(torch.sum(y_hats, dim=0)).numpy())\n",
    "        predicted_truth.append(targets[i].numpy())\n",
    "    print(epoch, \": \", correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
